{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW9q8qD_bPhY"
      },
      "source": [
        "**Locally Hosted Semantic Reranker**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf09mgBb5Bb9"
      },
      "source": [
        "# Objectives\n",
        "\n",
        "In this notebook we will:\n",
        "- Load a semantic reranker into Elasticsearch with Eland\n",
        "- Create a reranker inference API\n",
        "- Modify the query to use the reranker as part of the query to gather contextual documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BecBOzyDbWik"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Here we do the following\n",
        "- Import the required libraries\n",
        "- Create an elasticsearch python client connection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ayhDP72bZAe"
      },
      "source": [
        "These should already be installed in your notebook environment.\n",
        "You can uncomment and run if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2Xz9uWQFbNkH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the '/Users/rajeshmenon/topramen/onboarding-search-1/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "zsh:1: no matches found: eland[pytorch]\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU elasticsearch\n",
        "%pip install -qU eland[pytorch]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgHQaJh0bmJQ"
      },
      "source": [
        "Import the required python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CsL466H0bjNX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from elasticsearch import Elasticsearch, helpers, exceptions\n",
        "from urllib.request import urlopen\n",
        "from getpass import getpass\n",
        "import json\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsQ4XIpkbpd4"
      },
      "source": [
        "Create an Elasticsearch Python client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "P8Pf-lDepKdv"
      },
      "outputs": [],
      "source": [
        "elastic_endpoint = os.getenv('ELASTIC_ENDPOINT')\n",
        "elastic_api_key = os.getenv('ELASTIC_API_KEY')\n",
        "\n",
        "es = Elasticsearch(\n",
        "    elastic_endpoint,\n",
        "    api_key=elastic_api_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bsLLnqCfNKk"
      },
      "source": [
        "# Upload Hugging Face model with Eland\n",
        "Here, we will:\n",
        "- Upload the model from Hugging Face to Elasticsearch\n",
        "- Use Eland's `eland_import_hub_model` command to upload the model to Elasticsearch.\n",
        "\n",
        "For this example we've chosen the [`cross-encoder/ms-marco-MiniLM-L-6-v2`](https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2) text similarity model.\n",
        "<br><br>\n",
        "**Note**:\n",
        "While we are importing the model for use as a reranker, Eland and Elasticsearch do not have a dedicated rerank task type, so we still use `text_similarity`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "J2MTEYrUfk9R"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"cohere/rerank-english-v2.0\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "!eland_import_hub_model \\\n",
        "  --url $elastic_endpoint \\\n",
        "  --es-api-key $elastic_api_key \\\n",
        "  --hub-model-id $MODEL_ID \\\n",
        "  --task-type text_similarity \\\n",
        "  --start \\\n",
        "  --clear-previous\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rrQV6SAgWz8"
      },
      "source": [
        "# Create Inference Endpoint\n",
        "Here we will:\n",
        "- Create an inference Endpoint\n",
        "- Deploy the reranking model we impoted in the previous section\n",
        "We need to create an endpoint queries can use for reranking\n",
        "\n",
        "Key points about the `model_config`\n",
        "- `service` - in this case `elasticsearch` will tell the inference API to use a locally hosted (in Elasticsearch) model\n",
        "- `num_allocations` sets the number of allocations to 1\n",
        "    - Allocations are independent units of work for NLP tasks. Scaling this allows for an increase in concurrent throughput\n",
        "- `num_threads` - sets the number of threads per allocation to 1\n",
        "    - Threads per allocation affect the number of threads used by each allocation during inference. Scaling this generally increased the speed of inference requests (to a point).\n",
        "- `model_id` - This is the id of the model as it is named in Elasticsearch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Abu084BYgWCE"
      },
      "outputs": [],
      "source": [
        "model_config = {\n",
        "  \"service\": \"elasticsearch\",\n",
        "  \"service_settings\": {\n",
        "    \"num_allocations\": 1,\n",
        "    \"num_threads\": 1,\n",
        "    \"model_id\": \"cross-encoder__ms-marco-minilm-l-6-v2\"\n",
        "  },\n",
        "      \"task_settings\": {\n",
        "        \"return_documents\": True\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'inference_id': 'semantic-reranking',\n",
              " 'task_type': 'rerank',\n",
              " 'service': 'elasticsearch',\n",
              " 'service_settings': {'num_allocations': 1,\n",
              "  'num_threads': 1,\n",
              "  'model_id': 'cross-encoder__ms-marco-minilm-l-6-v2'},\n",
              " 'task_settings': {'return_documents': True}}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "inference_id = \"semantic-reranking\"\n",
        "\n",
        "create_endpoint = es.inference.put(\n",
        "    inference_id=inference_id,\n",
        "    task_type=\"rerank\",\n",
        "    body=model_config\n",
        ")\n",
        "\n",
        "create_endpoint.body"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8rQXMrHhMkS"
      },
      "source": [
        "###Verify it was created\n",
        "\n",
        "- Run the two cells in this section to verify:\n",
        "- The Inference Endpoint has been completed\n",
        "- The model has been deployed\n",
        "\n",
        "You should see JSON output with information about the semantic endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "n3Yk7rgYhP-N"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'endpoints': [{'inference_id': 'semantic-reranking',\n",
              "   'task_type': 'rerank',\n",
              "   'service': 'elasticsearch',\n",
              "   'service_settings': {'num_allocations': 1,\n",
              "    'num_threads': 1,\n",
              "    'model_id': 'cross-encoder__ms-marco-minilm-l-6-v2'},\n",
              "   'task_settings': {'return_documents': True}}]}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "check_endpoint = es.inference.get(\n",
        "    inference_id=inference_id,\n",
        ")\n",
        "\n",
        "check_endpoint.body"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dqYN5B4gI7v"
      },
      "source": [
        "Verify the model was successfully deployed\n",
        "\n",
        "The cell below should return `started`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "tui0K4JIgNmf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pprint==0.7.0 (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pprint==0.7.0\u001b[0m\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the '/Users/rajeshmenon/topramen/onboarding-search-1/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "ObjectApiResponse({'count': 1, 'trained_model_stats': [{'model_id': 'cross-encoder__ms-marco-minilm-l-6-v2', 'model_size_stats': {'model_size_bytes': 90892372, 'required_native_memory_bytes': 1229655976}, 'pipeline_count': 0, 'inference_stats': {'failure_count': 0, 'inference_count': 0, 'cache_miss_count': 0, 'missing_all_fields_count': 0, 'timestamp': 1728062249227}, 'deployment_stats': {'deployment_id': 'semantic-reranking', 'model_id': 'cross-encoder__ms-marco-minilm-l-6-v2', 'threads_per_allocation': 1, 'number_of_allocations': 1, 'queue_capacity': 1024, 'state': 'starting', 'reason': 'Could not assign (more) allocations on node [HyWdEyhFS1Wp5gd5Ih4CKg]. Reason: This node has insufficient allocated processors. Available processors [32], free processors [0], processors required for each allocation of this model [1]', 'allocation_status': {'allocation_count': 0, 'target_allocation_count': 1, 'state': 'starting'}, 'cache_size': '86.6mb', 'priority': 'normal', 'start_time': 1728059862522, 'peak_throughput_per_minute': 0, 'nodes': []}}, {'model_id': 'cross-encoder__ms-marco-minilm-l-6-v2', 'model_size_stats': {'model_size_bytes': 90892372, 'required_native_memory_bytes': 1229655976}, 'pipeline_count': 0, 'inference_stats': {'failure_count': 0, 'inference_count': 0, 'cache_miss_count': 0, 'missing_all_fields_count': 0, 'timestamp': 1728062249227}, 'deployment_stats': {'deployment_id': 'cross-encoder__ms-marco-minilm-l-6-v2', 'model_id': 'cross-encoder__ms-marco-minilm-l-6-v2', 'threads_per_allocation': 8, 'number_of_allocations': 2, 'queue_capacity': 1024, 'state': 'started', 'reason': 'Could not assign (more) allocations on node [HyWdEyhFS1Wp5gd5Ih4CKg]. Reason: This node has insufficient allocated processors. Available processors [32], free processors [0], processors required for each allocation of this model [8]', 'allocation_status': {'allocation_count': 1, 'target_allocation_count': 2, 'state': 'started'}, 'cache_size': '86.6mb', 'priority': 'normal', 'start_time': 1727995750890, 'peak_throughput_per_minute': 0, 'nodes': [{'node': {'HyWdEyhFS1Wp5gd5Ih4CKg': {'name': 'instance-0000000005', 'ephemeral_id': 'Z-WKgUucQG6VYCt3WbmKuQ', 'transport_address': '10.42.14.113:19833', 'external_id': 'instance-0000000005', 'attributes': {'xpack.installed': 'true', 'transform.config_version': '10.0.0', 'server_name': 'instance-0000000005.448b18343d5f44fb9cb98a9ace2068f3', 'availability_zone': 'us-central1-a', 'ml.config_version': '12.0.0', 'logical_availability_zone': 'zone-0', 'instance_configuration': 'gcp.es.ml.n2.68x32x45', 'ml.allocated_processors_double': '32.0', 'ml.machine_memory': '68028465152', 'ml.max_jvm_size': '11953766400', 'ml.allocated_processors': '32', 'region': 'unknown-region'}, 'roles': ['ml', 'remote_cluster_client'], 'version': '8.15.0', 'min_index_version': 7000099, 'max_index_version': 8512000}}, 'routing_state': {'routing_state': 'started'}, 'inference_count': 0, 'inference_cache_hit_count': 0, 'number_of_pending_requests': 0, 'start_time': 1727995773592, 'threads_per_allocation': 8, 'number_of_allocations': 1, 'peak_throughput_per_minute': 0, 'throughput_last_minute': 0, 'inference_cache_hit_count_last_minute': 0}]}}]})\n"
          ]
        }
      ],
      "source": [
        "ES_MODEL_ID = \"cross-encoder__ms-marco-minilm-l-6-v2\"\n",
        "\n",
        "model_info = es.ml.get_trained_models_stats(model_id=ES_MODEL_ID)\n",
        "\n",
        "%pip install jello\n",
        "from jello import jprint\n",
        "jprint(model_info)\n",
        "# model_info.body['trained_model_stats'][0]['deployment_stats']['nodes'][0]['routing_state']['routing_state']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bwvzLfRjJ2n"
      },
      "source": [
        "# Query with Reranking\n",
        "\n",
        "This containes a `text_similarity_reranker` retriever which:\n",
        "1. Uses a Standard Retriever to :\n",
        "    1. Perform a semantic query against the chunked ELSER embeddings\n",
        "    2. Return the top 2 inner hit chunks\n",
        "2. Perform a reranking:\n",
        "    1. Taks as input the top 50 results from the previous search\n",
        "      - `\"rank_window_size\": 50`\n",
        "    2. Taks as input the uer's question\n",
        "      - `\"inference_text\": USER_QUESTION`\n",
        "    3.  Uses our previously created reranking API and model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWXQBS35jQ3n"
      },
      "outputs": [],
      "source": [
        "USER_QUESTION = \"Where can I get good pizza?\"\n",
        "\n",
        "response = es.search(\n",
        "    index=\"restaurant_reviews\",\n",
        "    body={\n",
        "      \"retriever\": {\n",
        "        \"text_similarity_reranker\": {\n",
        "          \"retriever\": {\n",
        "            \"standard\": {\n",
        "              \"query\": {\n",
        "                    \"nested\": {\n",
        "                        \"path\": \"semantic_body.inference.chunks\",\n",
        "                        \"query\": {\n",
        "                            \"knn\": {\n",
        "                                \"field\": \"semantic_body.inference.chunks.embeddings\",\n",
        "                                \"query_vector_builder\": {\n",
        "                                    \"text_embedding\": {\n",
        "                                        \"model_id\": \"my-e5-endpoint\",\n",
        "                                        \"model_text\": USER_QUESTION\n",
        "                                    }\n",
        "                                }\n",
        "                            }\n",
        "                        },\n",
        "                        \"inner_hits\": {\n",
        "                            \"size\": 2,\n",
        "                            \"name\": \"restaurant_reviews.semantic_body\",\n",
        "                            \"_source\": [\n",
        "                                \"semantic_body.inference.chunks.text\"\n",
        "                            ]\n",
        "                        }\n",
        "                    }\n",
        "\n",
        "\n",
        "\n",
        "              }\n",
        "            }\n",
        "          },\n",
        "          \"field\": \"Review\",\n",
        "          \"inference_id\": \"semantic-reranking\",\n",
        "          \"inference_text\": USER_QUESTION,\n",
        "          \"rank_window_size\": 50\n",
        "        }\n",
        "      }\n",
        "    }\n",
        ")\n",
        "\n",
        "response.raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0HyNZoWyeun"
      },
      "source": [
        "Print out the formatted response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZEx-46rn3in"
      },
      "outputs": [],
      "source": [
        "for review in response.raw['hits']['hits']:\n",
        "    print(f\"Restaurant {review['_source']['Restaurant']} - Rating: {review['_source']['Rating']} - Reviewer: {review['_source']['Reviewer']}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
